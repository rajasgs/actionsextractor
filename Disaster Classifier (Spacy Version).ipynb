{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# I saved all PDF files under the PDF folder in my env directory\n",
    "pdf_docs_path = os.path.join(\"PDF\")\n",
    "one_pdf_path = os.path.join(pdf_docs_path,\"protect-your-home-from-snow-ice-storms.pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This file has 16 pages.\n"
     ]
    }
   ],
   "source": [
    "# Trying a better result with pdftotext\n",
    "import pdftotext\n",
    "\n",
    "with open(one_pdf_path, \"rb\") as f:\n",
    "    pdf = pdftotext.PDF(f)\n",
    "    \n",
    "print(\"This file has\", len(pdf), \"pages.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PDFtoText is much better than PyPDF, with automatic ligature conversion!\n",
    "# Now we can get rid of new lines and stray spaces\n",
    "\n",
    "import re\n",
    "\n",
    "docText = \"\"\n",
    "for page in pdf:\n",
    "    docText = docText + re.sub('\\s+', ' ', page).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "import string\n",
    "\n",
    "# Loads text with linguistic annotations from Spacy\n",
    "my_doc = nlp(docText)\n",
    "\n",
    "filteredDoc = []\n",
    "\n",
    "for sentence in my_doc.sents:\n",
    "    for word in sentence:\n",
    "        if not(word.is_stop) and (word.pos_=='NOUN' or word.pos_=='PROPN'):\n",
    "            filteredDoc.append(word.text.lower())\n",
    "\n",
    "nounsFreqDistribution = Counter(filteredDoc)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'home': 35,\n",
       "         'snow': 33,\n",
       "         'ice': 48,\n",
       "         'storms': 2,\n",
       "         'living': 9,\n",
       "         'program': 6,\n",
       "         'canada': 10,\n",
       "         'insurers': 6,\n",
       "         'disaster': 12,\n",
       "         'homes.for': 1,\n",
       "         'loss': 12,\n",
       "         'reduction': 4,\n",
       "         'institute': 6,\n",
       "         'catastrophic': 4,\n",
       "         'iclr': 5,\n",
       "         'world': 2,\n",
       "         'class': 1,\n",
       "         'centre': 2,\n",
       "         'multidisciplinary': 1,\n",
       "         'prevention': 3,\n",
       "         'research': 3,\n",
       "         'communication': 2,\n",
       "         'profit': 1,\n",
       "         'insurance': 3,\n",
       "         'industry': 1,\n",
       "         'university': 2,\n",
       "         'western': 2,\n",
       "         'ontario': 6,\n",
       "         'mission': 1,\n",
       "         'life': 1,\n",
       "         'property': 7,\n",
       "         'weather': 25,\n",
       "         'earthquakes': 2,\n",
       "         'identification': 2,\n",
       "         'support': 2,\n",
       "         'actions': 5,\n",
       "         'society': 1,\n",
       "         'capacity': 3,\n",
       "         'anticipate': 1,\n",
       "         'disasters': 3,\n",
       "         'mandate': 1,\n",
       "         'increase': 1,\n",
       "         'losses': 2,\n",
       "         'deaths': 1,\n",
       "         'injuries': 1,\n",
       "         'damage': 24,\n",
       "         'years': 1,\n",
       "         '1960s': 1,\n",
       "         'trend': 1,\n",
       "         'tragedy': 1,\n",
       "         'development': 1,\n",
       "         'knowledge': 2,\n",
       "         'homeowner': 5,\n",
       "         'hazards': 1,\n",
       "         'homeowners': 27,\n",
       "         'steps': 7,\n",
       "         'family': 1,\n",
       "         'purpose': 1,\n",
       "         'handbook': 2,\n",
       "         'homes': 8,\n",
       "         'winter': 24,\n",
       "         'measures': 1,\n",
       "         'money': 1,\n",
       "         'risk': 3,\n",
       "         'cover': 1,\n",
       "         'photos': 1,\n",
       "         'superstock': 1,\n",
       "         'corbus': 2,\n",
       "         'images': 2,\n",
       "         'waiver': 1,\n",
       "         'responsibility': 1,\n",
       "         'liability': 1,\n",
       "         'person': 1,\n",
       "         'result': 3,\n",
       "         'information': 2,\n",
       "         'reliance': 1,\n",
       "         'pamphlet': 1,\n",
       "         'injury': 2,\n",
       "         'death': 1,\n",
       "         'structures': 1,\n",
       "         'document': 1,\n",
       "         'isbn': 1,\n",
       "         'copyright': 1,\n",
       "         'Â®': 3,\n",
       "         'reductionfor': 1,\n",
       "         'challenge': 2,\n",
       "         'canadians': 3,\n",
       "         'temperatures': 7,\n",
       "         'snowfall': 4,\n",
       "         'build': 4,\n",
       "         'ups': 1,\n",
       "         'sources': 6,\n",
       "         'pipes': 24,\n",
       "         'water': 27,\n",
       "         'leaks': 5,\n",
       "         'roof': 61,\n",
       "         'preparation': 1,\n",
       "         'forms': 2,\n",
       "         'cold': 2,\n",
       "         'quebec': 2,\n",
       "         'storm': 3,\n",
       "         'example': 3,\n",
       "         'history': 1,\n",
       "         'layer': 2,\n",
       "         'rain': 2,\n",
       "         'hydro': 1,\n",
       "         'towers': 1,\n",
       "         'electricity': 1,\n",
       "         'telephone': 1,\n",
       "         'lines': 2,\n",
       "         'people': 1,\n",
       "         'new': 1,\n",
       "         'brunswick': 1,\n",
       "         'power': 5,\n",
       "         'areas': 5,\n",
       "         'c': 6,\n",
       "         'prince': 1,\n",
       "         'edward': 1,\n",
       "         'island': 1,\n",
       "         'snaps': 5,\n",
       "         'temperature': 9,\n",
       "         'periods': 3,\n",
       "         'time': 3,\n",
       "         'battle': 1,\n",
       "         'ruptures': 1,\n",
       "         'precaution': 1,\n",
       "         'gap': 1,\n",
       "         'extreme': 2,\n",
       "         'scorecard': 1,\n",
       "         'vulnerability': 1,\n",
       "         'vulnerabilities': 2,\n",
       "         'collapse': 7,\n",
       "         'dams': 11,\n",
       "         'threats': 3,\n",
       "         'government': 3,\n",
       "         'governments': 1,\n",
       "         'advice': 3,\n",
       "         'websites': 1,\n",
       "         'works': 1,\n",
       "         'utilities': 1,\n",
       "         'building': 3,\n",
       "         'department': 1,\n",
       "         'towns': 1,\n",
       "         'cities': 1,\n",
       "         'belt': 1,\n",
       "         'regions': 1,\n",
       "         'amounts': 1,\n",
       "         'deal': 1,\n",
       "         'expertise': 2,\n",
       "         'relief': 1,\n",
       "         'assistance': 1,\n",
       "         'contractors': 1,\n",
       "         'protection': 4,\n",
       "         'defenses': 1,\n",
       "         'agent': 1,\n",
       "         'broker': 1,\n",
       "         'agents': 1,\n",
       "         'brokers': 1,\n",
       "         'types': 2,\n",
       "         'policy': 2,\n",
       "         'municipality': 2,\n",
       "         'subdivision': 1,\n",
       "         'inspector': 2,\n",
       "         'inspectors': 2,\n",
       "         'insights': 1,\n",
       "         'age': 1,\n",
       "         'ie': 1,\n",
       "         'interior': 4,\n",
       "         'plumbing': 3,\n",
       "         'loads': 2,\n",
       "         'way': 1,\n",
       "         'area': 2,\n",
       "         'safety': 1,\n",
       "         'integrity': 1,\n",
       "         'melts': 2,\n",
       "         'pipe': 4,\n",
       "         'bursts': 1,\n",
       "         'series': 2,\n",
       "         'events': 1,\n",
       "         'season': 1,\n",
       "         'step': 2,\n",
       "         'accumulation': 2,\n",
       "         'slope': 5,\n",
       "         'factor': 1,\n",
       "         'photo': 2,\n",
       "         'bill': 1,\n",
       "         'jarvis': 1,\n",
       "         'builders': 1,\n",
       "         'cm': 4,\n",
       "         'obstructions': 4,\n",
       "         'chimneys': 4,\n",
       "         'skylights': 2,\n",
       "         'dormers': 2,\n",
       "         'ones': 1,\n",
       "         'vents': 1,\n",
       "         'gables': 1,\n",
       "         'aftermath': 1,\n",
       "         'event': 2,\n",
       "         'indicators': 2,\n",
       "         'stress': 2,\n",
       "         'canadian': 2,\n",
       "         'mortgage': 2,\n",
       "         'housing': 2,\n",
       "         'corporation': 3,\n",
       "         'cmhc': 2,\n",
       "         'house': 12,\n",
       "         'door': 4,\n",
       "         'jams': 1,\n",
       "         'doors': 4,\n",
       "         'cracks': 3,\n",
       "         'drywall': 2,\n",
       "         'plaster': 1,\n",
       "         'load': 2,\n",
       "         'weight': 1,\n",
       "         'roofs': 2,\n",
       "         'ridge': 3,\n",
       "         'line': 3,\n",
       "         'sides': 1,\n",
       "         'meet': 1,\n",
       "         'indication': 1,\n",
       "         'action': 1,\n",
       "         'approach': 3,\n",
       "         'removal': 2,\n",
       "         'contractor': 2,\n",
       "         'rake': 1,\n",
       "         'arm': 1,\n",
       "         'ground': 1,\n",
       "         'drainage': 8,\n",
       "         'impact': 1,\n",
       "         'http://www.cmhc': 1,\n",
       "         'schl.gc.ca': 1,\n",
       "         'co': 1,\n",
       "         '/': 1,\n",
       "         'maho': 1,\n",
       "         'gemare_006.cfmthe': 1,\n",
       "         'advantage': 1,\n",
       "         'paths': 1,\n",
       "         'electric': 1,\n",
       "         'heating': 5,\n",
       "         'cables': 5,\n",
       "         'design': 1,\n",
       "         'experience': 1,\n",
       "         'chemical': 1,\n",
       "         'de': 4,\n",
       "         'icers': 1,\n",
       "         'hole': 2,\n",
       "         'feet': 1,\n",
       "         'surface': 1,\n",
       "         '-': 2,\n",
       "         'icer': 2,\n",
       "         'edge': 2,\n",
       "         'resort': 1,\n",
       "         'option': 1,\n",
       "         'process': 1,\n",
       "         'dam': 3,\n",
       "         'drains': 2,\n",
       "         'heat': 16,\n",
       "         'permission': 1,\n",
       "         'science': 1,\n",
       "         'www.buildingscience.com': 1,\n",
       "         'escapes': 1,\n",
       "         'attic': 17,\n",
       "         'combination': 1,\n",
       "         'air': 11,\n",
       "         'circulation': 1,\n",
       "         'cause': 1,\n",
       "         'edges': 2,\n",
       "         'contact': 1,\n",
       "         'eave': 1,\n",
       "         'freeze': 2,\n",
       "         'leak': 2,\n",
       "         'walls': 2,\n",
       "         'ceilings': 4,\n",
       "         'addition': 2,\n",
       "         'snowloads': 1,\n",
       "         'pressure': 1,\n",
       "         'structure': 2,\n",
       "         'strategy': 1,\n",
       "         'penetrations': 5,\n",
       "         'stacks': 1,\n",
       "         'service': 1,\n",
       "         'source': 1,\n",
       "         'incandescent': 1,\n",
       "         'light': 4,\n",
       "         'fixtures': 4,\n",
       "         'ceiling': 2,\n",
       "         'insulation': 9,\n",
       "         'fixture': 1,\n",
       "         'form': 1,\n",
       "         'penetration': 2,\n",
       "         'vent': 3,\n",
       "         'sunlight': 1,\n",
       "         'outside': 3,\n",
       "         'roofing': 1,\n",
       "         'opportunity': 1,\n",
       "         'installation': 1,\n",
       "         'moisture': 1,\n",
       "         'barrier': 2,\n",
       "         'layers': 1,\n",
       "         'underlayment': 1,\n",
       "         'shield': 1,\n",
       "         'valleys': 1,\n",
       "         'problem': 1,\n",
       "         'fibre': 3,\n",
       "         'glass': 3,\n",
       "         'batt': 1,\n",
       "         'joists': 1,\n",
       "         'maintenance': 2,\n",
       "         'measure': 1,\n",
       "         'systems': 5,\n",
       "         'scuppers': 2,\n",
       "         'gutters': 4,\n",
       "         'spouts': 1,\n",
       "         'debris': 5,\n",
       "         'working': 1,\n",
       "         'blockages': 2,\n",
       "         'trees': 2,\n",
       "         'vegetation': 3,\n",
       "         'type': 1,\n",
       "         'case': 2,\n",
       "         'cable': 1,\n",
       "         'gutter': 1,\n",
       "         'downspout': 1,\n",
       "         '7frozen': 1,\n",
       "         'frozen': 1,\n",
       "         'freezes': 1,\n",
       "         'blockage': 1,\n",
       "         'rupture': 2,\n",
       "         'number': 3,\n",
       "         'system': 4,\n",
       "         'drop': 1,\n",
       "         'closet': 1,\n",
       "         'tape': 1,\n",
       "         'options': 1,\n",
       "         'attics': 1,\n",
       "         'partition': 1,\n",
       "         'wall': 3,\n",
       "         'stack': 1,\n",
       "         'chases': 1,\n",
       "         'access': 3,\n",
       "         'fire': 1,\n",
       "         'conduits': 1,\n",
       "         'disconnect': 2,\n",
       "         'garden': 2,\n",
       "         'hoses': 2,\n",
       "         'valves': 2,\n",
       "         'control': 2,\n",
       "         'flow': 2,\n",
       "         'valve': 3,\n",
       "         'faucet': 2,\n",
       "         'drops': 1,\n",
       "         'attention': 1,\n",
       "         'forecasts': 1,\n",
       "         'taps': 4,\n",
       "         'drip': 1,\n",
       "         'thermostat': 5,\n",
       "         'day': 3,\n",
       "         'night': 3,\n",
       "         'sinks': 1,\n",
       "         'appliances': 1,\n",
       "         'kitchen': 2,\n",
       "         'sink': 1,\n",
       "         'cabinets': 2,\n",
       "         'garage': 3,\n",
       "         'period': 2,\n",
       "         'return': 1,\n",
       "         'ways': 1,\n",
       "         '12c': 1,\n",
       "         'neighbour': 2,\n",
       "         'outages': 2,\n",
       "         'celcius': 1,\n",
       "         'causes': 1,\n",
       "         'supply': 2,\n",
       "         'montreal': 1,\n",
       "         'generator': 1,\n",
       "         'monitoring': 1,\n",
       "         'companies': 1,\n",
       "         'notification': 1,\n",
       "         'sprinkler': 1,\n",
       "         'station': 1,\n",
       "         'repair': 4,\n",
       "         'list': 1,\n",
       "         'description': 3,\n",
       "         'location': 3,\n",
       "         'start': 3,\n",
       "         'date': 3,\n",
       "         'upgrade': 3,\n",
       "         'budgeted': 3,\n",
       "         'actual': 3,\n",
       "         'cost': 3,\n",
       "         '10and': 1,\n",
       "         'plan': 2,\n",
       "         'b': 3,\n",
       "         'd': 2,\n",
       "         'f': 2,\n",
       "         'e': 2,\n",
       "         'g': 2,\n",
       "         'h': 2,\n",
       "         'determine': 1,\n",
       "         'cut': 1,\n",
       "         'piping': 1,\n",
       "         'examine': 1,\n",
       "         'evidence': 1,\n",
       "         'damming': 1,\n",
       "         'explore': 1,\n",
       "         'gaps': 1,\n",
       "         '11of': 1,\n",
       "         'assign': 1,\n",
       "         'points': 2,\n",
       "         'question': 2,\n",
       "         'score': 2,\n",
       "         'yes': 1,\n",
       "         'downspouts': 1,\n",
       "         'overhangs': 1,\n",
       "         'un': 1,\n",
       "         'checks': 1,\n",
       "         'low': 1,\n",
       "         'moderate': 1,\n",
       "         'high': 1,\n",
       "         'notes': 1,\n",
       "         'institut': 1,\n",
       "         'prÃ©vention': 1,\n",
       "         'sinistres': 1,\n",
       "         'catastrophiques': 1,\n",
       "         'toronto': 2,\n",
       "         'office': 2,\n",
       "         'london': 2,\n",
       "         'richmond': 1,\n",
       "         'street': 1,\n",
       "         'east': 1,\n",
       "         'boundry': 1,\n",
       "         'wind': 2,\n",
       "         'tunnel': 1,\n",
       "         'laboratory': 1,\n",
       "         'suite': 1,\n",
       "         'm5c': 1,\n",
       "         'n6a': 1,\n",
       "         'info@iclr.org': 1,\n",
       "         'www.iclr.org': 1,\n",
       "         'firesmart': 1,\n",
       "         'basement': 1,\n",
       "         'flooding': 1,\n",
       "         'wildfire': 1,\n",
       "         'severe': 1,\n",
       "         'Â¤': 1,\n",
       "         'funding': 1,\n",
       "         'natural': 1,\n",
       "         'resources': 1,\n",
       "         'climate': 1,\n",
       "         'change': 1,\n",
       "         'impacts': 1,\n",
       "         'adaptation': 1})"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nounsFreqDistribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roof, ice, home, snow, water, weather, damage, winter, pipes, homeowners, attic, heat, house, disaster, dams, air, Canada, living, temperature, insulation, homes, drainage, loss, property, steps, temperatures, collapse, Ontario, sources, C, Homeowners, program, insurers, Loss, Institute, ICLR, actions, homeowner, leaks, areas, snaps, slope, Ice, penetrations, systems, debris, thermostat, Reduction, Catastrophic, snowfall, \n"
     ]
    }
   ],
   "source": [
    "listOfWords=\"\"\n",
    "for word in nounsFreqDistribution.most_common(50):\n",
    "    listOfWords = listOfWords + word[0] + \", \"\n",
    "print (listOfWords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, what if we devise a dictionary of relevant nouns that apply to disaster types, and constrain the results to that list? Let's try with this..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('roof', 57)\n",
      "('ice', 43)\n",
      "('home', 34)\n",
      "('snow', 30)\n",
      "('water', 26)\n",
      "('weather', 25)\n",
      "('damage', 24)\n",
      "('winter', 23)\n",
      "('heat', 14)\n",
      "('disaster', 11)\n",
      "('temperature', 9)\n",
      "('drainage', 8)\n"
     ]
    }
   ],
   "source": [
    "dictionary = [\"snow\",\"change\",\"climate\",\"heatwave\",\"adaptation\",\"tornado\",\"water\",\"icestorm\",\"risk\",\"impact\",\"level\",\"community\",\"land\",\"management\",\"planning\",\"development\",\"http\",\"plan\",\"infrastructure\",\"sea\",\"event\",\"action\",\"vulnerability\",\"flood\",\"assessment\",\"storm\",\"temperature\",\"rise\",\"resource\",\"weather\",\"strategy\",\"damage\",\"effect\",\"precipitation\",\"hazard\",\"ice\",\"protection\",\"home\",\"flooding\",\"erosion\",\"environment\",\"emission\",\"al\",\"winter\",\"heat\",\"forest\",\"wind\",\"mitigation\",\"emergency\",\"coast\",\"shoreline\",\"greenhouse\",\"elevation\",\"carbon\",\"wave\",\"dike\",\"wetland\",\"disaster\",\"conservation\",\"reduction\",\"fire\",\"rain\",\"drainage\",\"ground\",\"power\",\"stormwater\",\"roof\",\"rainfall\",\"extreme\",\"wildfire\",\"reference\",\"vegetation\",\"threat\",\"drought\",\"disease\",\"coastline\",\"sewer\",\"nature\",\"neutral\",\"neutrality\"]\n",
    "\n",
    "for distWord in nounsFreqDistribution.most_common(50):\n",
    "    if distWord[0] in dictionary:\n",
    "        print(distWord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a function for frequent word extraction, returning a simple string:\n",
    "def frequentClimateWordsExtractor(text):\n",
    "    from collections import Counter\n",
    "    import spacy\n",
    "    from spacy.lang.en.stop_words import STOP_WORDS\n",
    "    import string\n",
    "    \n",
    "    # Dictionary of relevant words\n",
    "    dictionary = [\"snow\",\"change\",\"climate\",\"heatwave\",\"adaptation\",\"tornado\",\"water\",\"icestorm\",\"risk\",\"impact\",\"level\",\"community\",\"land\",\"management\",\"planning\",\"development\",\"http\",\"plan\",\"infrastructure\",\"sea\",\"event\",\"action\",\"vulnerability\",\"flood\",\"assessment\",\"storm\",\"temperature\", \"low\",\"rise\",\"resource\",\"weather\",\"strategy\",\"damage\",\"effect\",\"precipitation\",\"hazard\",\"ice\",\"protection\",\"home\",\"flooding\",\"erosion\",\"environment\",\"emission\",\"al\",\"winter\",\"heat\",\"forest\",\"wind\",\"mitigation\",\"emergency\",\"coast\",\"shoreline\",\"greenhouse\",\"elevation\",\"carbon\",\"wave\",\"dike\",\"wetland\",\"disaster\",\"conservation\",\"reduction\",\"fire\",\"rain\",\"drainage\",\"ground\",\"power\",\"stormwater\",\"roof\",\"rainfall\",\"extreme\",\"wildfire\",\"reference\",\"vegetation\",\"threat\",\"drought\",\"disease\",\"coastline\",\"sewer\",\"nature\",\"neutral\",\"neutrality\"]\n",
    "\n",
    "    # Loads text with linguistic annotations from Spacy\n",
    "    my_doc = nlp(text)\n",
    "\n",
    "    filteredDoc = []\n",
    "    filteredList = []\n",
    "    \n",
    "    # Returns a list with relevant words filtered by the dictionary\n",
    "    for sentence in my_doc.sents:\n",
    "        for word in sentence:\n",
    "            if not(word.is_stop) and (word.pos_=='NOUN' or word.pos_=='PROPN'):\n",
    "                filteredDoc.append(word.text.lower())\n",
    "\n",
    "    nounsFreqDistribution = Counter(filteredDoc)\n",
    "    \n",
    "    listOfWords=\"\"\n",
    "    for word in nounsFreqDistribution.most_common(300):\n",
    "        if word[0] in dictionary:\n",
    "            listOfWords = listOfWords + word[0] + \", \"\n",
    "            filteredList.append(word[0])\n",
    "    return listOfWords, filteredList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('snow, tornado, ', ['snow', 'tornado'])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequentClimateWordsExtractor(\"Snow may change the chances of a tornado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing all documents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's extract all words from all documents:\n",
    "import re\n",
    "import pandas as pd\n",
    "import pdftotext\n",
    "\n",
    "#allPagesCorpus = \"\"\n",
    "\n",
    "df = pd.DataFrame(columns=['File', 'Page', 'Text', 'Keywords'])\n",
    "acPage = 0\n",
    "\n",
    "with os.scandir(pdf_docs_path) as entries:\n",
    "    for entry in entries:\n",
    "        if entry.name != \".DS_Store\":\n",
    "            # Extract text and add to the datastore\n",
    "            document = entry.name\n",
    "            one_pdf_path = os.path.join(pdf_docs_path, document)\n",
    "            \n",
    "            with open(one_pdf_path, \"rb\") as f:\n",
    "                try:\n",
    "                    pdf = pdftotext.PDF(f)\n",
    "                    i=0\n",
    "                    for page in pdf:\n",
    "                        i+=1\n",
    "                        contents = re.sub(r\"[^a-zA-Z0-9:.,!?%$@]+\", ' ', page)\n",
    "                        if contents != \"\":\n",
    "                            #allPagesCorpus = allPagesCorpus + contents\n",
    "                            acPage+=1\n",
    "                            keywords, wordList = frequentClimateWordsExtractor(contents)\n",
    "                            df.loc[acPage] = [document,i,contents,keywords]\n",
    "                except:\n",
    "                    print(\"Error on document\",document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel(\"all-pages-freqdist.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trying a simple rule-based approach to disaster classification\n",
    "def disasterType(key_arr):\n",
    "    # Undefined to start with\n",
    "    \n",
    "    disaster_class = \"Undefined\"\n",
    "    numDetected = 0\n",
    "\n",
    "    if \"carbon\" in key_arr and (\"neutral\" in key_arr or \"neutrality\" in key_arr):\n",
    "        disaster_class = \"Carbon Neutrality\"\n",
    "        numDetected+=1\n",
    "        \n",
    "    if \"adaptation\" in key_arr and (\"change\" in key_arr or \"plan\" in key_arr):\n",
    "        disaster_class = \"Climate Change Adaptation\"\n",
    "        numDetected+=1\n",
    "        \n",
    "    if \"drought\" in key_arr:\n",
    "        disaster_class = \"Drought\"\n",
    "        numDetected+=1\n",
    "        \n",
    "    if \"flood\" in key_arr or \"flooding\" in key_arr or \"rainfall\" in key_arr or \"stormwater\" in key_arr or (\"sea\" in key_arr and \"level\" in key_arr and \"rise\" in key_arr):\n",
    "        disaster_class = \"Flooding\"\n",
    "        numDetected+=1\n",
    "        \n",
    "    if \"heat\" in key_arr or \"heatwave\" in key_arr:\n",
    "        disaster_class = \"Heatwave\"\n",
    "        numDetected+=1\n",
    "        \n",
    "    if \"mitigation\" in key_arr:\n",
    "        disaster_class = \"Mitigation\"\n",
    "        numDetected+=1\n",
    "        \n",
    "    if \"wind\" in key_arr or \"tornado\" in key_arr:\n",
    "        disaster_class = \"Severe Wind\"\n",
    "        numDetected+=1\n",
    "        \n",
    "    if \"snow\" in key_arr or \"snowstorm\" in key_arr:\n",
    "        disaster_class = \"Snowstorm\"\n",
    "        numDetected+=1\n",
    "\n",
    "    if \"temperature\" in key_arr and \"low\" in key_arr:\n",
    "        disaster_class = \"Low Temperatures\"\n",
    "        numDetected+=1\n",
    "\n",
    "\n",
    "    if \"fire\" in key_arr or \"wildfire\" in key_arr:\n",
    "        disaster_class = \"Wildfire\"\n",
    "        numDetected+=1\n",
    "        \n",
    "    if numDetected > 1:\n",
    "        disaster_class = \"Multiple\"\n",
    "        \n",
    "    if \"http\" in key_arr or \"al\" in key_arr or \"reference\" in key_arr:\n",
    "        disaster_class = \"References\"\n",
    "    \n",
    "    return disaster_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now exporting again with disaster class:\n",
    "import re\n",
    "import pandas as pd\n",
    "import pdftotext\n",
    "\n",
    "#allPagesCorpus = \"\"\n",
    "\n",
    "df = pd.DataFrame(columns=['File', 'Page', 'Text', 'Keywords', \"Disaster\"])\n",
    "acPage = 0\n",
    "\n",
    "with os.scandir(pdf_docs_path) as entries:\n",
    "    for entry in entries:\n",
    "        if entry.name != \".DS_Store\":\n",
    "            # Extract text and add to the datastore\n",
    "            document = entry.name\n",
    "            one_pdf_path = os.path.join(pdf_docs_path, document)\n",
    "            \n",
    "            with open(one_pdf_path, \"rb\") as f:\n",
    "                try:\n",
    "                    pdf = pdftotext.PDF(f)\n",
    "                    i=0\n",
    "                    for page in pdf:\n",
    "                        i+=1\n",
    "                        contents = re.sub(r\"[^a-zA-Z0-9:.,!?%$@]+\", ' ', page)\n",
    "                        if contents != \"\":\n",
    "                            #allPagesCorpus = allPagesCorpus + contents\n",
    "                            acPage+=1\n",
    "                            keywords, wordList = frequentClimateWordsExtractor(contents)\n",
    "                            disasterClass = disasterType(wordList)\n",
    "                            df.loc[acPage] = [document,i,contents,keywords, disasterClass]\n",
    "                except:\n",
    "                    print(\"Error on document\",document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel(\"all-pages-freqdist-tagged.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the imperative sentence extractor function\n",
    "def impSentenceExtractor(someText):\n",
    "    import spacy\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    \n",
    "    doc = nlp(someText)\n",
    "    impSentList=[]\n",
    "    # Extract sentences from block of text\n",
    "    \n",
    "    for sentence in doc.sents:\n",
    "        if sentence[0].pos_=='VERB' and (sentence[0].tag_==\"VB\" or sentence[0].tag_==\"VBG\"):\n",
    "            impSentList.append(sentence.text)\n",
    "    \n",
    "    return impSentList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = impSentenceExtractor(\"Do this right. Protect your basement. Keep doors open. Look for any form of penetration between your attic and roof, such as a vent.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Protect your basement.',\n",
       " 'Keep doors open.',\n",
       " 'Look for any form of penetration between your attic and roof, such as a vent.']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing all documents, classifying every page and outputting imperative sentences for every page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now exporting again with disaster class AND imperative sentences\n",
    "import re\n",
    "import pandas as pd\n",
    "import pdftotext\n",
    "\n",
    "#allPagesCorpus = \"\"\n",
    "\n",
    "df = pd.DataFrame(columns=['File', 'Page', 'Text', 'Keywords', \"Disaster\", \"Actions\"])\n",
    "acPage = 0\n",
    "\n",
    "with os.scandir(pdf_docs_path) as entries:\n",
    "    for entry in entries:\n",
    "        if entry.name != \".DS_Store\":   \n",
    "            # Extract text and add to the datastore\n",
    "            document = entry.name\n",
    "            one_pdf_path = os.path.join(pdf_docs_path, document)\n",
    "            \n",
    "            with open(one_pdf_path, \"rb\") as f:\n",
    "                try:\n",
    "                    pdf = pdftotext.PDF(f)\n",
    "                    i=0\n",
    "                    for page in pdf:\n",
    "                        i+=1\n",
    "                        contents = re.sub(r\"[^a-zA-Z0-9:.,!?%$@]+\", ' ', page)\n",
    "                        if contents != \"\":\n",
    "                            #allPagesCorpus = allPagesCorpus + contents\n",
    "                            acPage+=1\n",
    "                            keywords, wordList = frequentClimateWordsExtractor(contents)\n",
    "                            disasterClass = disasterType(wordList)\n",
    "                            impSents = impSentenceExtractor(contents)\n",
    "                            df.loc[acPage] = [document,i,contents,keywords, disasterClass, impSents]\n",
    "                except:\n",
    "                    print(\"Error on document\",document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel(\"all-pages-freqdist-tagged-impsents.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And just for fun, exporting all to a JSON object on the fly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "acPage = 0\n",
    "jsonFiles = []\n",
    "\n",
    "with os.scandir(pdf_docs_path) as entries:\n",
    "    for entry in entries:\n",
    "        if entry.name != \".DS_Store\":\n",
    "        #if entry.name == \"protect-your-home-from-basement-flooding.pdf\":   \n",
    "            # Extract text and add to the datastore\n",
    "            document = entry.name\n",
    "            one_pdf_path = os.path.join(pdf_docs_path, document)\n",
    "\n",
    "            \n",
    "            with open(one_pdf_path, \"rb\") as f:\n",
    "                try:\n",
    "                    pdf = pdftotext.PDF(f)\n",
    "                    i=0\n",
    "                    jsonObject = {}\n",
    "                    jsonObject['file'] = document\n",
    "                    jsonObject['pages'] = []\n",
    "                    \n",
    "                    for page in pdf:\n",
    "                        pageContent = {}\n",
    "                        i+=1\n",
    "                        contents = re.sub(r\"[^a-zA-Z0-9:.,!?%$@]+\", ' ', page)\n",
    "                        if contents != \"\":\n",
    "                            #allPagesCorpus = allPagesCorpus + contents\n",
    "                            acPage+=1\n",
    "                            keywords, wordList = frequentClimateWordsExtractor(contents)\n",
    "                            disasterClass = disasterType(wordList)\n",
    "                            impSents = impSentenceExtractor(contents)\n",
    "                            pageContent['page'] = i\n",
    "                            #pageContent['text'] = contents\n",
    "                            pageContent['disasterType'] = disasterClass\n",
    "                            pageContent['actions'] = impSents\n",
    "                            \n",
    "                            # Only output if there are actions and disaster type is not Undefined\n",
    "                            if len(impSents) != 0 and disasterClass != \"Undefined\" and disasterClass != \"References\":\n",
    "                                jsonObject['pages'].append(pageContent)\n",
    "                    \n",
    "                    jsonFiles.append(jsonObject)\n",
    "                except:\n",
    "                    print(\"Error on document\",document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "343604"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save JSON to file\n",
    "f=open(\"all-actions.json\", 'w', encoding=\"utf-8\")\n",
    "f.write(str(jsonFiles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
